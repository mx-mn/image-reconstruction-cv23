{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P99wDod7uhnz",
        "outputId": "c8504ac8-d97c-45cf-bcad-f1bcc9e920e5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))\n",
        "\n",
        "base = Path.cwd() / 'drive' / 'MyDrive' / 'cvue23' / 'data'\n",
        "base.exists()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "p7MK0yc5tadN",
        "outputId": "7baa7aab-bb61-4923-fcea-a25accc3ad84"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for debugging\n",
        "def plot_image_grid(images_array, grid_width=10, grid_height=10):\n",
        "\n",
        "    if images_array.shape[0] != grid_width * grid_height:\n",
        "        raise ValueError(\"The number of images does not match the grid size.\")\n",
        "\n",
        "    fig, axes = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
        "\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(images_array[i], cmap='gray', interpolation='none')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def load_data(path):\n",
        "  # load the mini dataset\n",
        "  loaded = np.load(path)\n",
        "  x, y, labels = loaded['x'], loaded['y'], loaded['labels']\n",
        "\n",
        "  # normalize dataset\n",
        "  assert y.max() == 255\n",
        "  assert x.max() == 255\n",
        "\n",
        "  y = y / 255\n",
        "  x = x / 255\n",
        "  return x, y, labels\n",
        "\n",
        "def encoder(x, num_features, num_layers, residual_every=2):\n",
        "    x = Conv2D(num_features, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "\n",
        "    # Save the output of conv layers at even indices\n",
        "    residuals = []\n",
        "\n",
        "    # Encoder\n",
        "    for i in range(num_layers - 1):\n",
        "        x = Conv2D(num_features, kernel_size=3, padding='same', activation='relu')(x)\n",
        "        if (i + 1) % residual_every == 0:\n",
        "            residuals.append(x)\n",
        "\n",
        "    return x, residuals\n",
        "\n",
        "def decoder(x, num_features, num_layers, residuals, residual_every=2):\n",
        "\n",
        "    # Decoder\n",
        "    for i in range(num_layers - 1):\n",
        "        x = Conv2DTranspose(num_features, kernel_size=3, padding='same')(x)\n",
        "\n",
        "        if (i + 1 + num_layers) % residual_every == 0 and residuals:\n",
        "            res = residuals.pop()\n",
        "            x = Add()([x, res])\n",
        "\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    if residuals: raise ValueError('There are unused residual connections')\n",
        "\n",
        "    # create 1-channel output\n",
        "    x = Conv2DTranspose(1, kernel_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def REDNet(num_layers, num_features, channel_size):\n",
        "    '''Model definition with keras functional layers api'''\n",
        "\n",
        "    inputs = Input(shape=(None, None, channel_size))\n",
        "\n",
        "    x, residuals = encoder(inputs, num_features, num_layers)\n",
        "\n",
        "    x = decoder(x, num_features, num_layers, residuals)\n",
        "\n",
        "    # Add input residual, needed to do 1x1 conv to adapt channels\n",
        "    residual = Conv2DTranspose(1, kernel_size=1, padding='same')(inputs)\n",
        "    outputs = Add()([x, residual])\n",
        "    outputs = Activation('relu')(outputs)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=f'REDNet{num_layers*2}')\n",
        "    return model\n",
        "\n",
        "class PredictionCallback(Callback):\n",
        "    def __init__(self, interval, x_val, y_val):\n",
        "        super(PredictionCallback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.x_val = x_val\n",
        "        self.y_val = y_val\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            preds = self.model.predict(self.x_val).squeeze()\n",
        "            plot_image_grid(np.concatenate([self.y_val, preds]), preds.shape[0], 2)\n",
        "\n",
        "\n",
        "def load(path: Path, normalize=True):\n",
        "    # load the mini dataset\n",
        "    loaded = np.load(path)\n",
        "    x, y, labels = loaded['x'], loaded['y'], loaded['labels']\n",
        "\n",
        "    if normalize:\n",
        "        y = y / 255\n",
        "        x = x / 255\n",
        "\n",
        "    return x, y, labels\n",
        "\n",
        "def sort_by_number(path):\n",
        "        return int(str(path.stem).split('_')[-1])\n",
        "\n",
        "\n",
        "class AOSPyDataset(keras.utils.PyDataset):\n",
        "\n",
        "    def __init__(self, files, batch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.files = files\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return number of batches.\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        low = idx * self.batch_size\n",
        "        high = min(low + self.batch_size, len(self.x))\n",
        "\n",
        "        batch = self.files[low:high]\n",
        "        x, y = [],[]\n",
        "        for f in batch:\n",
        "            x,y,_ = load(f)\n",
        "            x.append(x)\n",
        "            y.append(y)\n",
        "\n",
        "        return np.stack(x), np.stack(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1g4CmB05UUir",
        "outputId": "41ce8b62-0765-4dbb-aa0b-514d7f0ced65"
      },
      "outputs": [],
      "source": [
        "paths = [f for f in (base / 'crop_1').iterdir() if f.is_file()]\n",
        "paths = list(sorted(paths, key=sort_by_number))\n",
        "aos_dataset = AOSPyDataset(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1RuZQWzwBxX"
      },
      "outputs": [],
      "source": [
        "x_val, y_val, val_labels = load_data(base / 'part_1_original_test_100.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-1D9y9dvuyA"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model = REDNet(\n",
        "    num_layers=5,\n",
        "    num_features=64,\n",
        "    channel_size=x_val.shape[-1]\n",
        ")\n",
        "\n",
        "opt = keras.optimizers.Adam(\n",
        "    learning_rate=0.0001\n",
        ")\n",
        "\n",
        "loss = keras.losses.MeanSquaredError(\n",
        "    reduction=\"sum_over_batch_size\",\n",
        "    name=\"mse\"\n",
        ")\n",
        "\n",
        "prediction_callback = PredictionCallback(interval=10, x_val=x_val[:30], y_val=y_val[:30])\n",
        "#prediction_callback = PredictionCallback(interval=10, x_val=x_train[:30], y_val=y_train[:30])\n",
        "\n",
        "\n",
        "model.compile(loss=loss,optimizer=opt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "WdV3uwPPv2AO",
        "outputId": "168a33aa-36f5-4ce3-9d7a-baf03f683a6c"
      },
      "outputs": [],
      "source": [
        "# train on the dataset\n",
        "\n",
        "batch_size=16\n",
        "history = model.fit(\n",
        "    x=DataLoader(aos_dataset, batch_size, shuffle=True),\n",
        "    epochs=1,\n",
        "    #validation_split=0.1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[prediction_callback]\n",
        ")\n",
        "# Save the weights\n",
        "model.save_weights(base.parent / 'models' / 'new')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('MSE Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xwUbeU7yMK0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RB7zvrY20mGS",
        "outputId": "0cf95723-3fbc-4439-8c20-5838f76997fb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfau8Jrm2EH8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubKgJzZ4E5VM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgHeDya4E5na"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
