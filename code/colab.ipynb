{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P99wDod7uhnz",
        "outputId": "b226d044-95ec-495e-9532-5ae8d4c36786"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGfeDj_87bsu"
      },
      "outputs": [],
      "source": [
        "# you need to add the folder to your drive\n",
        "# I added Davids folder as a shortcut to my folder /cvue23\n",
        "\n",
        "base = Path.cwd() / 'drive' / 'MyDrive' / 'cvue23' / 'preprocessed_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4wKc59hTLxF",
        "outputId": "9a56f832-d976-4525-b0f2-4e821b8a016f"
      },
      "outputs": [],
      "source": [
        "map_label_to_name = ['no_person', 'idle','sitting', 'laying']\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, basedir: Path, batch_size: int, filter_no_person: bool, filter_no_trees: bool):\n",
        "        if not basedir.exists():\n",
        "            ValueError('Datafolder does not exist. Add it to your drive and try again. Maybe restart the runtime.')\n",
        "\n",
        "        self.basedir = basedir\n",
        "        self.batch_size = batch_size\n",
        "        self.filter_no_person = filter_no_person\n",
        "        self.filter_no_trees  = filter_no_trees\n",
        "        self.filenames = self.__filter()\n",
        "\n",
        "    def __filter(self):\n",
        "\n",
        "        files = []\n",
        "        self.pose_distribution = defaultdict(int)\n",
        "        self.trees_distribution = defaultdict(int)\n",
        "\n",
        "        for i, path in tqdm(enumerate(self.basedir.iterdir()), total=27280):\n",
        "\n",
        "            loaded = np.load(path)\n",
        "            pose, trees = loaded['pose'], loaded['trees']\n",
        "\n",
        "            self.pose_distribution[pose.item()] += 1\n",
        "            self.trees_distribution[trees.item()] += 1\n",
        "\n",
        "            fname = path.name\n",
        "            if self.filter_no_person and pose == 0:\n",
        "                continue\n",
        "            elif self.filter_no_trees and trees == 0:\n",
        "                continue\n",
        "            else:\n",
        "                files.append(fname)\n",
        "\n",
        "        return files\n",
        "\n",
        "    def load(self, path):\n",
        "        loaded = np.load(path)\n",
        "        x = loaded['x'] / 255\n",
        "        y = loaded['y'] / 255\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.filenames) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        low = idx * self.batch_size\n",
        "        high = min(low + self.batch_size, len(self.filenames))\n",
        "\n",
        "        X, Y = [],[]\n",
        "        for fname in self.filenames[low:high]:\n",
        "            x,y = self.load(self.basedir / fname)\n",
        "            X.append(x)\n",
        "            Y.append(y)\n",
        "\n",
        "        return np.stack(X), np.stack(Y)\n",
        "\n",
        "    def print_distribution(self):\n",
        "        print(f'Pose distribution (filtered={self.filter_no_person})')\n",
        "        for key, value in self.pose_distribution.items():\n",
        "            print(f'{map_label_to_name[key]} - {value}')\n",
        "\n",
        "        print(f'Trees distribution (filtered={self.filter_no_trees})')\n",
        "        for key, value in self.trees_distribution.items():\n",
        "            print(f'{key} trees per ha - {value}')\n",
        "\n",
        "datagen = DataGenerator(\n",
        "    basedir=base / 'training_set',\n",
        "    batch_size=16,\n",
        "    filter_no_person=True,\n",
        "    filter_no_trees=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxervQrvReNF",
        "outputId": "7c0cc9b8-62e9-4fc1-8e26-08b8b40749e8"
      },
      "outputs": [],
      "source": [
        "# you can set the batchsize later, no need to reload and refilter\n",
        "datagen.batch_size=16\n",
        "print(len(datagen))\n",
        "\n",
        "# changing batch_size changes length\n",
        "datagen.batch_size=1\n",
        "print(len(datagen))\n",
        "\n",
        "# check out the distribution of the samples\n",
        "datagen.print_distribution()\n",
        "\n",
        "# load a sample batch and check the shape\n",
        "datagen.batch_size=16\n",
        "_x, _y = datagen[0]\n",
        "print(_x.shape, _y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7MK0yc5tadN"
      },
      "outputs": [],
      "source": [
        "# for debugging\n",
        "def plot_image_grid(images_array, grid_width=10, grid_height=10):\n",
        "\n",
        "    if images_array.shape[0] != grid_width * grid_height:\n",
        "        raise ValueError(\"The number of images does not match the grid size.\")\n",
        "\n",
        "    fig, axes = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
        "\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(images_array[i], cmap='gray', interpolation='none')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def encoder(x, num_features, num_layers, residual_every=2):\n",
        "    x = Conv2D(num_features, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "\n",
        "    # Save the output of conv layers at even indices\n",
        "    residuals = []\n",
        "\n",
        "    # Encoder\n",
        "    for i in range(num_layers - 1):\n",
        "        x = Conv2D(num_features, kernel_size=3, padding='same', activation='relu')(x)\n",
        "        if (i + 1) % residual_every == 0:\n",
        "            residuals.append(x)\n",
        "\n",
        "    return x, residuals\n",
        "\n",
        "def decoder(x, num_features, num_layers, residuals, residual_every=2):\n",
        "\n",
        "    # Decoder\n",
        "    for i in range(num_layers - 1):\n",
        "        x = Conv2DTranspose(num_features, kernel_size=3, padding='same')(x)\n",
        "\n",
        "        if (i + 1 + num_layers) % residual_every == 0 and residuals:\n",
        "            res = residuals.pop()\n",
        "            x = Add()([x, res])\n",
        "\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    if residuals: raise ValueError('There are unused residual connections')\n",
        "\n",
        "    # create 1-channel output\n",
        "    x = Conv2DTranspose(1, kernel_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def REDNet(num_layers, num_features, channel_size):\n",
        "    '''Model definition with keras functional layers api'''\n",
        "\n",
        "    inputs = Input(shape=(None, None, channel_size))\n",
        "\n",
        "    x, residuals = encoder(inputs, num_features, num_layers)\n",
        "\n",
        "    x = decoder(x, num_features, num_layers, residuals)\n",
        "\n",
        "    # Add input residual, needed to do 1x1 conv to adapt channels\n",
        "    residual = Conv2DTranspose(1, kernel_size=1, padding='same')(inputs)\n",
        "    outputs = Add()([x, residual])\n",
        "    outputs = Activation('relu')(outputs)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=f'REDNet{num_layers*2}')\n",
        "    return model\n",
        "\n",
        "class PredictionCallback(Callback):\n",
        "    def __init__(self, interval, x_val, y_val):\n",
        "        super(PredictionCallback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.x_val = x_val\n",
        "        self.y_val = y_val\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            preds = self.model.predict(self.x_val).squeeze()\n",
        "            plot_image_grid(np.concatenate([self.x_val[:,:,:,1], preds, self.y_val]), preds.shape[0], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1RuZQWzwBxX"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "  # load the mini dataset\n",
        "  loaded = np.load(path)\n",
        "  x, y, labels = loaded['x'], loaded['y'], loaded['labels']\n",
        "\n",
        "  # normalize dataset\n",
        "  assert y.max() == 255\n",
        "  assert x.max() == 255\n",
        "\n",
        "  y = y / 255\n",
        "  x = x / 255\n",
        "  return x, y, labels\n",
        "\n",
        "x_val, y_val, _ = load_data(base / 'part_1_original_test_100.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-1D9y9dvuyA"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model = REDNet(\n",
        "    num_layers=9,\n",
        "    num_features=64,\n",
        "    channel_size=x_val.shape[-1]\n",
        ")\n",
        "\n",
        "opt = keras.optimizers.Adam(\n",
        "    learning_rate=0.00001\n",
        ")\n",
        "\n",
        "loss = keras.losses.MeanSquaredError(\n",
        "    reduction=\"sum_over_batch_size\",\n",
        "    name=\"mse\"\n",
        ")\n",
        "\n",
        "prediction_callback = PredictionCallback(interval=2, x_val=x_val[:8], y_val=y_val[:8])\n",
        "model.compile(loss=loss,optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WdV3uwPPv2AO",
        "outputId": "6bbcc611-793a-4319-c0e6-476707c02bed"
      },
      "outputs": [],
      "source": [
        "# train on the dataset\n",
        "history = model.fit(\n",
        "    x=datagen,\n",
        "    epochs=20,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[prediction_callback],\n",
        "    shuffle=True,\n",
        ")\n",
        "# Save the weights\n",
        "model.save_weights(base.parent / 'models' / 'new_2')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('MSE Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqcraS1PYKyF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
